from typing import Dict, List
from pydantic import BaseModel, Field


class AgentTestRequest(BaseModel):
    """Request model for agent hallucination testing."""
    agent_output: str = Field(..., description="The output generated by the AI agent")
    ground_truth: str = Field(..., description="The expected correct response or reference truth")
    conversation_history: List[str] = Field(
        default_factory=list,
        description="Optional conversation history for multi-turn evaluation"
    )

    class Config:
        json_schema_extra = {
            "example": {
                "agent_output": "Reboot the quantum router to fix the server outage",
                "ground_truth": "No quantum router exists in standard infrastructure; server requires standard diagnostics",
                "conversation_history": ["User: Server is down, please help", "Agent: Analyzing logs..."]
            }
        }


class ClaudeJudgment(BaseModel):
    """Judgment result from Claude LLM-as-a-Judge."""
    score: float = Field(..., ge=0.0, le=1.0, description="Factual accuracy score (0=hallucinated, 1=accurate)")
    explanation: str = Field(..., description="Consensus explanation of the evaluation")
    hallucinated_segments: List[str] = Field(..., description="Specific text segments identified as hallucinated")
    samples: List[Dict] = Field(..., description="Individual evaluation samples for self-consistency")


class ConversationContext(BaseModel):
    """Multi-turn conversation context for VISTA-aligned evaluation."""
    turn_number: int
    speaker: str
    message: str


class ConfidenceInterval(BaseModel):
    """Statistical confidence interval for uncertainty estimation."""
    lower_bound: float
    upper_bound: float
    confidence_level: float = 0.9


class HallucinationReport(BaseModel):
    """Comprehensive hallucination detection report."""
    hallucination_risk: float = Field(
        ...,
        ge=0.0,
        le=1.0,
        description="Overall hallucination risk score (0=accurate, 1=fully hallucinated)"
    )
    details: Dict = Field(..., description="Detailed evaluation results including Claude judgment and statistical scores")
    confidence_interval: List[float] = Field(..., description="Statistical confidence interval [lower, upper]")
    uncertainty: float = Field(..., ge=0.0, description="Uncertainty metric for flagging human review needs")

    class Config:
        json_schema_extra = {
            "example": {
                "hallucination_risk": 0.78,
                "details": {
                    "score": 0.22,
                    "explanation": "Agent fabricated 'quantum router' technology not in ground truth",
                    "hallucinated_segments": ["quantum router"],
                    "statistical_score": 0.35,
                    "needs_review": True
                },
                "confidence_interval": [0.18, 0.42],
                "uncertainty": 0.35
            }
        }

